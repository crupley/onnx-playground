{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Spark-ONNX\n",
    "\n",
    "Note: this notebook uses multiple kernels/languages:\n",
    "\n",
    "* [sos-notebook](https://github.com/vatlab/sos-notebook) : super-kernel that allows multiple sub-kernels\n",
    "    * [toree](https://toree.incubator.apache.org/) : scala kernel with spark\n",
    "    * [python](https://jupyter.org/) : default jupyter python kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "# export iris dataset from sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "df = pd.DataFrame(X)\n",
    "df['label'] = y\n",
    "\n",
    "df.to_csv('data/iris.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "kernel": "Apache Toree - Scala"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.2\n"
     ]
    }
   ],
   "source": [
    "println(spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Apache Toree - Scala"
   },
   "source": [
    "# Train Spark Model in Spark-Scala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "kernel": "Apache Toree - Scala"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 0: double (nullable = true)\n",
      " |-- 1: double (nullable = true)\n",
      " |-- 2: double (nullable = true)\n",
      " |-- 3: double (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n",
      "+---+---+---+---+-----+\n",
      "|  0|  1|  2|  3|label|\n",
      "+---+---+---+---+-----+\n",
      "|5.1|3.5|1.4|0.2|    0|\n",
      "|4.9|3.0|1.4|0.2|    0|\n",
      "|4.7|3.2|1.3|0.2|    0|\n",
      "|4.6|3.1|1.5|0.2|    0|\n",
      "|5.0|3.6|1.4|0.2|    0|\n",
      "+---+---+---+---+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dfLoad = [0: double, 1: double ... 3 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[0: double, 1: double ... 3 more fields]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "val dfLoad = spark.read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .load(\"data/iris.csv\")\n",
    "    \n",
    "dfLoad.printSchema()\n",
    "dfLoad.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "kernel": "Apache Toree - Scala"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|         features|label|\n",
      "+-----------------+-----+\n",
      "|[5.1,3.5,1.4,0.2]|    0|\n",
      "|[4.9,3.0,1.4,0.2]|    0|\n",
      "|[4.7,3.2,1.3,0.2]|    0|\n",
      "|[4.6,3.1,1.5,0.2]|    0|\n",
      "|[5.0,3.6,1.4,0.2]|    0|\n",
      "+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "assembler = vecAssembler_f5fc70deebd6\n",
       "df = [features: vector, label: int]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[features: vector, label: int]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.VectorAssembler\n",
    "\n",
    "val assembler = new VectorAssembler()\n",
    "    .setInputCols(Array(\"0\", \"1\", \"2\", \"3\"))\n",
    "    .setOutputCol(\"features\")\n",
    "    \n",
    "val df = assembler.transform(dfLoad)\n",
    "    .select(\"features\", \"label\")\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "kernel": "Apache Toree - Scala"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train = [features: vector, label: int]\n",
       "test = [features: vector, label: int]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[features: vector, label: int]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val Array(train, test) = df.randomSplit(Array(0.7, 0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "kernel": "Apache Toree - Scala"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+--------------------+--------------------+----------+\n",
      "|         features|label|       rawPrediction|         probability|prediction|\n",
      "+-----------------+-----+--------------------+--------------------+----------+\n",
      "|[4.4,2.9,1.4,0.2]|    0|[34.8163862311835...|[0.99999999999996...|       0.0|\n",
      "|[4.6,3.1,1.5,0.2]|    0|[37.8819563292555...|[0.99999999999999...|       0.0|\n",
      "|[4.6,3.2,1.4,0.2]|    0|[40.9887864583076...|[1.0,8.5418181641...|       0.0|\n",
      "|[4.8,3.0,1.4,0.3]|    0|[33.5381692382255...|[0.99999999999974...|       0.0|\n",
      "|[4.8,3.4,1.9,0.2]|    0|[41.3059111545101...|[1.0,1.5760202039...|       0.0|\n",
      "+-----------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "lr = logreg_7bb8d7a88798\n",
       "pipe = pipeline_160e25e5b788\n",
       "model = pipeline_160e25e5b788\n",
       "predictions = [features: vector, label: int ... 3 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[features: vector, label: int ... 3 more fields]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.classification.LogisticRegression\n",
    "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
    "\n",
    "val lr = new LogisticRegression()\n",
    "val pipe = new Pipeline()\n",
    "    .setStages(Array(lr))\n",
    "\n",
    "val model = pipe.fit(train)\n",
    "model.write.overwrite().save(\"models/spark-lr\")\n",
    "\n",
    "val predictions = model.transform(test)\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "kernel": "Apache Toree - Scala"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set accuracy: 0.9761904761904762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "metrics = org.apache.spark.mllib.evaluation.MulticlassMetrics@13ed6538\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.mllib.evaluation.MulticlassMetrics@13ed6538"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.mllib.evaluation.MulticlassMetrics\n",
    "\n",
    "val metrics = new MulticlassMetrics(predictions.select(\"label\", \"prediction\").as[(Double, Double)].rdd)\n",
    "println(s\"test set accuracy: ${metrics.accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Apache Toree - Scala"
   },
   "source": [
    "# Convert to onnx model\n",
    "\n",
    "https://github.com/onnx/onnxmltools\n",
    "\n",
    "https://github.com/onnx/onnxmltools/tree/master/onnxmltools/convert/sparkml\n",
    "\n",
    "https://github.com/onnx/onnxmltools/blob/master/docs/examples/plot_convert_sparkml.py\n",
    "\n",
    "\n",
    "```bash\n",
    "pip install onnxmltools\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+--------------------+--------------------+----------+\n",
      "|         features|label|       rawPrediction|         probability|prediction|\n",
      "+-----------------+-----+--------------------+--------------------+----------+\n",
      "|[5.1,3.5,1.4,0.2]|    0|[45.5310525224865...|[1.0,3.3008935103...|       0.0|\n",
      "|[4.9,3.0,1.4,0.2]|    0|[34.5192147381927...|[0.99999999999986...|       0.0|\n",
      "|[4.7,3.2,1.3,0.2]|    0|[41.1325197544599...|[1.0,1.1391290863...|       0.0|\n",
      "|[4.6,3.1,1.5,0.2]|    0|[37.8819563292555...|[0.99999999999999...|       0.0|\n",
      "|[5.0,3.6,1.4,0.2]|    0|[48.4941493553864...|[1.0,4.2034642524...|       0.0|\n",
      "+-----------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load and test model using pyspark\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# load model\n",
    "model = PipelineModel.load(\"models/spark-lr\")\n",
    "\n",
    "# load and reformat data\n",
    "dfLoad = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"data/iris.csv\")\n",
    "    \n",
    "assembler = VectorAssembler() \\\n",
    "    .setInputCols([\"0\", \"1\", \"2\", \"3\"]) \\\n",
    "    .setOutputCol(\"features\")\n",
    "    \n",
    "df = assembler.transform(dfLoad) \\\n",
    "    .select(\"features\", \"label\")\n",
    "\n",
    "# predict\n",
    "predictions = model.transform(df)\n",
    "\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full set accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "metrics = MulticlassMetrics(predictions.select(\"label\", \"prediction\").rdd.map(lambda lp: (lp.prediction, float(lp.label))))\n",
    "print(f\"full set accuracy: {metrics.accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classlabels_ints': [0, 1, 2],\n",
      " 'coefficients': [-5.433780543151039,\n",
      "                  24.197187785847923,\n",
      "                  -6.871113504673745,\n",
      "                  -15.244235542823668,\n",
      "                  3.9842347508985205,\n",
      "                  -10.01934063212504,\n",
      "                  -0.3318504026548301,\n",
      "                  0.5345400721224732,\n",
      "                  1.449545792252519,\n",
      "                  -14.177847153722885,\n",
      "                  7.2029639073285745,\n",
      "                  14.709695470701195],\n",
      " 'intercepts': [1.2215820571970788, 15.779321387299293, -17.000903444496373],\n",
      " 'multi_class': 1,\n",
      " 'name': 'LinearClassifier',\n",
      " 'post_transform': 'LOGISTIC'}\n"
     ]
    }
   ],
   "source": [
    "# convert model and save in onnx format\n",
    "from onnxmltools.convert.common.data_types import FloatTensorType\n",
    "from onnxmltools import convert_sparkml\n",
    "\n",
    "initial_types = [ \n",
    "    #(\"label\", FloatTensorType([None, 1])), # error if provided\n",
    "    (\"features\", FloatTensorType([None, 4])) # why 4??\n",
    "]\n",
    "\n",
    "onnx_model = convert_sparkml(model, 'My Sparkml Pipeline', initial_types)\n",
    "\n",
    "with open(\"models/spark-lr.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "# convert data\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "# transform with onnx model\n",
    "import onnxruntime\n",
    "import numpy as np\n",
    "\n",
    "sess = onnxruntime.InferenceSession(onnx_model.SerializeToString())\n",
    "\n",
    "input_name = sess.get_inputs()[0].name\n",
    "label_name = sess.get_outputs()[0].name\n",
    "\n",
    "output = sess.run(None, {input_name: X.astype(np.float32)})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98\n",
      "Bal. Acc: 0.98\n"
     ]
    }
   ],
   "source": [
    "# evaluate predictions\n",
    "# note: portion of predictions are contained in the training set\n",
    "import sklearn.metrics\n",
    "\n",
    "print(\"Accuracy: {}\".format(sklearn.metrics.accuracy_score(y, output)))\n",
    "print(\"Bal. Acc: {}\".format(sklearn.metrics.balanced_accuracy_score(y, output)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50,  0,  0],\n",
       "       [ 0, 48,  2],\n",
       "       [ 0,  1, 49]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicted vs actual\n",
    "sklearn.metrics.confusion_matrix(y, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50,  0,  0],\n",
       "       [ 0, 49,  0],\n",
       "       [ 0,  0, 51]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spark transform vs onnx transform\n",
    "sklearn.metrics.confusion_matrix(predictions.select(\"prediction\").collect(), output) # identical!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Apache Toree - Scala",
     "apache_toree_scala",
     "scala",
     "",
     "text/x-scala"
    ],
    [
     "Python 3",
     "python3",
     "python3",
     "",
     {
      "name": "ipython",
      "version": 3
     }
    ]
   ],
   "version": "0.21.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
